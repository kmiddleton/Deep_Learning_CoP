{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "import plotnine as p9\n",
    "import statistics\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "num_epochs = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultivariateData(Dataset):\n",
    "\n",
    "  def __init__(self):\n",
    "    torch.manual_seed(100)\n",
    "    \n",
    "    n = 10000\n",
    "    self.x_data = torch.randn(n, 2)  # n samples, 2 features\n",
    "\n",
    "    # y = 2 * x1 + 3 * x2 + noise\n",
    "    self.y_data = 2 * self.x_data[:, 0] + 3 * self.x_data[:, 1] + torch.randn(n)\n",
    "    self.y_data = self.y_data.view(-1, 1)  # reshape to [100, 1]\n",
    "\n",
    "    self.n_samples = self.x_data.shape[0]\n",
    "\n",
    "  # Implement indexing so that dataset[i] can be used to get ith sample\n",
    "  def __getitem__(self, index):\n",
    "    return self.x_data[index], self.y_data[index]\n",
    "\n",
    "  # Implement len(dataset) to return the size\n",
    "  def __len__(self):\n",
    "    return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "dataset = MultivariateData()\n",
    "\n",
    "# get first sample and unpack\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load whole dataset with DataLoader\n",
    "# shuffle: shuffle data, good for training\n",
    "train_loader = DataLoader(dataset = dataset,\n",
    "                          batch_size = batch_size,\n",
    "                          shuffle = True)\n",
    "\n",
    "# Convert to an iterator and print at one batch\n",
    "data_iterator = iter(train_loader)\n",
    "data = next(data_iterator)\n",
    "features, labels = data\n",
    "print(features, \"\\n\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleRegressionModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(MultipleRegressionModel, self).__init__()\n",
    "    self.linear = nn.Linear(2, 1)\n",
    "        \n",
    "  def forward(self, x):\n",
    "    return self.linear(x)\n",
    "\n",
    "model = MultipleRegressionModel()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples / batch_size)\n",
    "print(total_samples, n_iterations)\n",
    "\n",
    "loss_values = []  # List to store loss values\n",
    "\n",
    "start_time = time.time()  # Record start time\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  for i, (inputs, labels) in enumerate(train_loader):\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # zero grad before new step\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # if (i + 1) % 10 == 0:\n",
    "    #   print(f'Epoch: {epoch + 1}/{num_epochs}, Step {i + 1}/{n_iterations} | Loss: {loss.item()}')\n",
    "\n",
    "  # Store loss value\n",
    "  loss_values.append(loss.item())\n",
    "\n",
    "end_time = time.time()  # Record end time\n",
    "\n",
    "training_time = end_time - start_time\n",
    "print(f'Batch size: {batch_size} | Training time: {training_time:.2f} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(5, 51.9),\n",
    "        (10, 28.39),\n",
    "        (25, 14.42),\n",
    "        (50, 9.56),\n",
    "        (100, 7.47),\n",
    "        (200, 5.95),\n",
    "        (300, 6.46),\n",
    "        (400, 6.32),\n",
    "        (500, 6.58),\n",
    "        (750, 6.73),\n",
    "        (1000, 7.66),\n",
    "        (1500, 7.44),\n",
    "        (2000, 7.99),\n",
    "        (3000, 9.77)]\n",
    "df_times = pd.DataFrame(data, columns=['Batch Size', 'Time'])\n",
    "\n",
    "p = (p9.ggplot(df_times, p9.aes(x = 'Batch Size', y = 'Time')) +\n",
    "  p9.geom_point(size = 4, color = 'firebrick') +\n",
    "  p9.labs(x = 'Batch Size', y = 'Training Time (s)') +\n",
    "  p9.theme_classic() +\n",
    "  p9.theme(figure_size = (8, 5)))\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = (p9.ggplot(p9.aes(x = range(1, num_epochs + 1), y = loss_values)) +\n",
    "      p9.geom_line(size = 1.5, color = 'firebrick') +\n",
    "      p9.labs(x = 'Epoch', y = 'Loss') +\n",
    "      p9.theme_classic() +\n",
    "      p9.theme(figure_size = (8, 5)))\n",
    "p2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_loss = statistics.mean(loss_values[100:])\n",
    "print(f'Mean loss for epochs 100 and above: {mean_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  # Define the input data pairs\n",
    "  pred_X = [[0, 0],   # 0 \n",
    "            [1, 1],   # 2 + 3 = 5\n",
    "            [2, 2],   # 4 + 6 = 10\n",
    "            [10, 20]] # 20 + 60 = 80\n",
    "  input_data = torch.tensor(pred_X, dtype=torch.float32)\n",
    "\n",
    "  # Generate predictions using the trained model\n",
    "  predictions = model(input_data).numpy()\n",
    "\n",
    "  # Print the predictions\n",
    "  print(np.round(predictions, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
