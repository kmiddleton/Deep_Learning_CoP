{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matmul: 0.07955529098398983\n",
      "dot: 0.05391174997203052\n",
      "einsum: 0.14371120801661164\n",
      "matmul: 0.07955529098398983\n",
      "dot: 0.05391174997203052\n",
      "einsum: 0.14371120801661164\n"
     ]
    }
   ],
   "source": [
    "# Define two matrices\n",
    "m1 = np.array([[1, 2], [3, 4]])\n",
    "m2 = np.array([[5, 6], [7, 8]])\n",
    "\n",
    "def f_dot():\n",
    "  result = np.dot(m1, m2)\n",
    "\n",
    "def f_matmul():\n",
    "  result = np.matmul(m1, m2)\n",
    "\n",
    "def f_einsum():\n",
    "  result = np.einsum('ij,jk->ik', m1, m2)\n",
    "\n",
    "n = 100000\n",
    "\n",
    "print(f'matmul: {timeit.timeit(f_matmul, number = n)}')\n",
    "print(f'dot: {timeit.timeit(f_dot, number = n)}')\n",
    "print(f'einsum: {timeit.timeit(f_einsum, number = n)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matmul: 0.6809974589850754\n",
      "matmul: 0.6809974589850754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dot: 0.5357569169718772\n",
      "dot: 0.5357569169718772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "einsum: 1.4327294999966398\n",
      "einsum: 1.4327294999966398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at: 0.638580167084001\n",
      "Are the outputs identical? True\n",
      "at: 0.638580167084001\n",
      "Are the outputs identical? True\n"
     ]
    }
   ],
   "source": [
    "# Define two matrices\n",
    "m1 = np.array([[1, 2, 3], [3, 4, 5]])\n",
    "m2 = np.array([[5, 6, 7], [7, 8, 9], [9, 10, 11]])\n",
    "def f_dot():\n",
    "  result = np.dot(m1, m2)\n",
    "def f_matmul():\n",
    "  result = np.matmul(m1, m2)\n",
    "def f_einsum():\n",
    "  result = np.einsum('ij,jk -> ik', m1, m2)\n",
    "def f_at():\n",
    "  result = m1 @ m2\n",
    "\n",
    "n = 1000000\n",
    "\n",
    "print(f'matmul: {timeit.timeit(f_matmul, number = n)}')\n",
    "print(f'dot: {timeit.timeit(f_dot, number = n)}')\n",
    "print(f'einsum: {timeit.timeit(f_einsum, number = n)}')\n",
    "print(f'at: {timeit.timeit(f_at, number = n)}')\n",
    "\n",
    "# Check if the outputs are identical\n",
    "output_dot = f_dot()\n",
    "output_matmul = f_matmul()\n",
    "output_einsum = f_einsum()\n",
    "\n",
    "print(f\"Are the outputs identical? {np.array_equal(output_dot, output_matmul) and np.array_equal(output_dot, output_einsum)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo of time.perf_counter()\n",
      "============================\n",
      "\n",
      "1. Basic timing of a simple operation:\n",
      "Time taken: 0.000663 seconds\n",
      "\n",
      "2. Timing a function:\n",
      "slow_function() took 0.105041 seconds\n",
      "\n",
      "3. Timing multiple iterations:\n",
      "Demo of time.perf_counter()\n",
      "============================\n",
      "\n",
      "1. Basic timing of a simple operation:\n",
      "Time taken: 0.000663 seconds\n",
      "\n",
      "2. Timing a function:\n",
      "slow_function() took 0.105041 seconds\n",
      "\n",
      "3. Timing multiple iterations:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time over 5 iterations: 0.102664 seconds\n",
      "\n",
      "4. Measuring time between checkpoints:\n",
      "Average time over 5 iterations: 0.102664 seconds\n",
      "\n",
      "4. Measuring time between checkpoints:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to checkpoint 1: 0.104817 seconds\n",
      "Time between checkpoints 1 and 2: 0.299447 seconds\n",
      "Time from checkpoint 2 to end: 0.139653 seconds\n",
      "Total time: 0.543917 seconds\n",
      "\n",
      "5. Demonstrating monotonicity:\n",
      "Difference between consecutive calls: 0.000000833 seconds\n",
      "Difference between consecutive calls: 0.000000125 seconds\n",
      "Difference between consecutive calls: 0.000000167 seconds\n",
      "Difference between consecutive calls: 0.000000167 seconds\n",
      "Time to checkpoint 1: 0.104817 seconds\n",
      "Time between checkpoints 1 and 2: 0.299447 seconds\n",
      "Time from checkpoint 2 to end: 0.139653 seconds\n",
      "Total time: 0.543917 seconds\n",
      "\n",
      "5. Demonstrating monotonicity:\n",
      "Difference between consecutive calls: 0.000000833 seconds\n",
      "Difference between consecutive calls: 0.000000125 seconds\n",
      "Difference between consecutive calls: 0.000000167 seconds\n",
      "Difference between consecutive calls: 0.000000167 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "def demo_perf_counter():\n",
    "    print(\"Demo of time.perf_counter()\")\n",
    "    print(\"============================\")\n",
    "\n",
    "    # Basic usage\n",
    "    print(\"\\n1. Basic timing of a simple operation:\")\n",
    "    start = time.perf_counter()\n",
    "    # Simulate some work\n",
    "    sum([i**2 for i in range(10000)])\n",
    "    end = time.perf_counter()\n",
    "    print(f\"Time taken: {end - start:.6f} seconds\")\n",
    "\n",
    "    # Timing a function\n",
    "    print(\"\\n2. Timing a function:\")\n",
    "    def slow_function():\n",
    "        time.sleep(0.1)  # Simulate some work\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    slow_function()\n",
    "    end = time.perf_counter()\n",
    "    print(f\"slow_function() took {end - start:.6f} seconds\")\n",
    "\n",
    "    # Timing multiple iterations\n",
    "    print(\"\\n3. Timing multiple iterations:\")\n",
    "    iterations = 5\n",
    "    total_time = 0\n",
    "    for _ in range(iterations):\n",
    "        start = time.perf_counter()\n",
    "        slow_function()\n",
    "        end = time.perf_counter()\n",
    "        total_time += (end - start)\n",
    "    print(f\"Average time over {iterations} iterations: {total_time/iterations:.6f} seconds\")\n",
    "\n",
    "    # Measuring time between checkpoints\n",
    "    print(\"\\n4. Measuring time between checkpoints:\")\n",
    "    start = time.perf_counter()\n",
    "    # Checkpoint 1\n",
    "    time.sleep(random.uniform(0.1, 0.3))\n",
    "    checkpoint1 = time.perf_counter()\n",
    "    # Checkpoint 2\n",
    "    time.sleep(random.uniform(0.2, 0.4))\n",
    "    checkpoint2 = time.perf_counter()\n",
    "    # End\n",
    "    time.sleep(random.uniform(0.1, 0.2))\n",
    "    end = time.perf_counter()\n",
    "\n",
    "    print(f\"Time to checkpoint 1: {checkpoint1 - start:.6f} seconds\")\n",
    "    print(f\"Time between checkpoints 1 and 2: {checkpoint2 - checkpoint1:.6f} seconds\")\n",
    "    print(f\"Time from checkpoint 2 to end: {end - checkpoint2:.6f} seconds\")\n",
    "    print(f\"Total time: {end - start:.6f} seconds\")\n",
    "\n",
    "    # Demonstrating monotonicity\n",
    "    print(\"\\n5. Demonstrating monotonicity:\")\n",
    "    times = [time.perf_counter() for _ in range(5)]\n",
    "    for i in range(1, len(times)):\n",
    "        print(f\"Difference between consecutive calls: {times[i] - times[i-1]:.9f} seconds\")\n",
    "\n",
    "demo_perf_counter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape=(1, 5, 32000)\n",
      "out.shape=(1, 5, 32000)\n"
     ]
    }
   ],
   "source": [
    "from typing import List, NamedTuple\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "class LayerWeights(NamedTuple):\n",
    "  attn_norm: jax.Array\n",
    "  ffn_norm: jax.Array\n",
    "  w_q_dhk: jax.Array\n",
    "  w_k_dhk: jax.Array\n",
    "  w_v_dhk: jax.Array\n",
    "  w_o_hkd: jax.Array\n",
    "  w1: jax.Array\n",
    "  w2: jax.Array\n",
    "  w3: jax.Array\n",
    "\n",
    "class XfmrWeights(NamedTuple):\n",
    "  tok_embeddings: jax.Array\n",
    "  layer_weights: List[LayerWeights]\n",
    "  norm: jax.Array\n",
    "  output: jax.Array\n",
    "\n",
    "def norm(x, w, eps: float = 1e-6):\n",
    "  return w * (x * jax.lax.rsqrt(jax.lax.pow(x, 2).mean(-1, keepdims=True) + eps))\n",
    "\n",
    "def attention(input_bld, params):\n",
    "    \"\"\"\n",
    "    B: batch size\n",
    "    L: sequence length\n",
    "    M: memory length \n",
    "    D: model dimension\n",
    "    H: number of attention heads in a layer\n",
    "    K: size of each attention key or value\n",
    "    \"\"\"\n",
    "    normalized_bld = norm(input_bld, params.attn_norm)\n",
    "    query_blhk = jnp.einsum('bld,dhk->blhk', normalized_bld, params.w_q_dhk)\n",
    "    key_blhk = jnp.einsum('bld,dhk->blhk', normalized_bld, params.w_k_dhk)\n",
    "    value_blhk = jnp.einsum('bld,dhk->blhk', normalized_bld, params.w_v_dhk)\n",
    "    logits_bhlm = jnp.einsum('blhk,bmhk->bhlm', query_blhk, key_blhk)\n",
    "    _, l, h, k = query_blhk.shape\n",
    "    logits_bhlm = logits_bhlm / jnp.sqrt(k)\n",
    "    mask = jnp.triu(jnp.ones((l, l)), k=1).astype(input_bld.dtype)\n",
    "    logits_bhlm = logits_bhlm - jnp.inf * mask[None, None, :, :]\n",
    "    weights_bhlm = jax.nn.softmax(logits_bhlm, axis=-1)\n",
    "    wtd_values_blhk = jnp.einsum('blhk,bhlm->blhk', value_blhk, weights_bhlm)\n",
    "    out_bld = jnp.einsum('blhk,hkd->bld', wtd_values_blhk, params.w_o_hkd)\n",
    "    return out_bld\n",
    "\n",
    "def ffn(x: jax.Array, w1: jax.Array, w2: jax.Array, w3: jax.Array) -> jax.Array:\n",
    "  return jnp.dot(jax.nn.silu(jnp.dot(x, w1)) * jnp.dot(x, w3), w2)\n",
    "\n",
    "def transformer(tokens: jax.Array, params: jax.Array) -> jax.Array:\n",
    "  x = params.tok_embeddings[tokens]\n",
    "  def scan_fn(h, layer_weights):\n",
    "    h += attention(h, layer_weights)\n",
    "    h += ffn(norm(h, layer_weights.ffn_norm), layer_weights.w1, layer_weights.w2, layer_weights.w3)\n",
    "    return h, None\n",
    "  h, _ = jax.lax.scan(scan_fn, x, params.layer_weights)\n",
    "  h = norm(h, params.norm)\n",
    "  logits = jnp.dot(h, params.output.T)\n",
    "  return logits\n",
    "\n",
    "vocab_size = 32000\n",
    "dim = 4096\n",
    "hidden_dim = 14336\n",
    "n_layers = 1\n",
    "n_heads = 32\n",
    "head_dim = dim // n_heads\n",
    "\n",
    "layer_weights = LayerWeights(\n",
    "  attn_norm=jnp.ones((n_layers, dim,)),\n",
    "  ffn_norm=jnp.ones((n_layers, dim,)),\n",
    "  w_q_dhk=jnp.zeros((n_layers, dim, n_heads, head_dim)),\n",
    "  w_k_dhk=jnp.zeros((n_layers, dim, n_heads, head_dim)),\n",
    "  w_v_dhk=jnp.zeros((n_layers, dim, n_heads, head_dim)),\n",
    "  w_o_hkd=jnp.zeros((n_layers, n_heads, head_dim, dim)),\n",
    "  w1=jnp.zeros((n_layers, dim, hidden_dim)),\n",
    "  w2=jnp.zeros((n_layers, hidden_dim, dim)),\n",
    "  w3=jnp.zeros((n_layers, dim, hidden_dim))\n",
    ")\n",
    "params = XfmrWeights(tok_embeddings = jnp.ones((vocab_size, dim)),\n",
    "                     layer_weights=layer_weights,\n",
    "                     norm=jnp.ones((dim,)),\n",
    "                     output=jnp.ones((vocab_size, dim)))\n",
    "tokens = jnp.array([[123,234,234,345,446]])\n",
    "out = transformer(tokens, params)\n",
    "print(f'{out.shape=}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
